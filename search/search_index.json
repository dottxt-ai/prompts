{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Prompts","text":""},{"location":"reference/","title":"Reference","text":""},{"location":"reference/dispatch/","title":"Model-based prompt dispatching","text":"<p>Different models often require different prompts to achieve a given task. They are, in essence, not different prompts in the sense that they are supposed to perform the same operation. In the same way we use <code>functools.singledispatch</code> to dispatch a functionality on the type of the first argument, it can be useful to dispatch the prompt on the model that is being used.</p> <p><code>prompts</code> provides a way to dispatch the prompt on the model:</p> <pre><code>import prompts\n\n\n@prompts.template\ndef a_simple_prompt(query: str):\n    \"\"\"&lt;s&gt;{{ query }}&lt;/s&gt;\"\"\"\n\n@a_simple_prompt.register(\"google/gemma-2-9b\")\ndef a_simple_prompt_gemma(query: str):\n    \"\"\"&lt;bos&gt;{{ query }}&lt;eos&gt;\"\"\"\n</code></pre> <p>Note</p> <p>Choosing BOS and EOS based on the model is better achieved by using special variables.</p>"},{"location":"reference/special_tokens/","title":"Handle special tokens","text":"<p>Tokens that indicate the beginning of a sequence, an end of sequence, that delineate user and assistant turns in a conversation, etc. are model-specific. This means that one needs to write a new prompt each time they use a new model, only replacing these special tokens. This is error-prone and leads to duplicated work.</p>"},{"location":"reference/special_tokens/#beginning-and-end-of-sequences","title":"Beginning and end of sequences","text":"<p><code>prompts</code> provides special variables in its templates that allows user to use special tokens in their prompts in a model-agnostic way:</p> <pre><code>import prompts\n\n\n@prompts.template\ndef a_simple_prompt(query: str):\n    \"\"\"{{ bos + query + eos }}\"\"\"\n\n\nprint(a_simple_prompt[\"mistralai/Mistral-7B-v0.1\"](\"question\"))\n# &lt;s&gt;question&lt;/s&gt;\n\nprint(a_simple_prompt[\"google/gemma-2-9b\"](\"question\"))\n# &lt;bos&gt;question&lt;eos&gt;\n</code></pre> <p>Registry</p> <p>The registry is currently limited to a few models. Please open an issue if you want to use <code>prompts</code> with a model that is not currently in the registry.</p>"},{"location":"reference/special_tokens/#chat-and-instruct-models","title":"Chat and Instruct models","text":"<p><code>prompts</code> also provides special variables <code>user</code>, <code>assistant</code> and <code>system</code> that are related to chat workflows, so you can design prompts with a chat format in a model-agnostic way:</p> <pre><code>import prompts\n\n\n@prompts.template\ndef simple_prompt(favorite: str):\n    \"\"\"{{ bos + user.begin}} What is your favorite {{favorite + '? ' + user.end}}\n    {{ assistant.begin }}\n    \"\"\"\n</code></pre> <p>Chat templates are so idiosyncratic, however, that we recommend using the <code>Chat</code> class to format according to chat templates.</p>"},{"location":"reference/template/","title":"Prompt templating","text":"<p>Prompts provides a powerful domain-specific language to write and manage prompts, via what we call prompt functions.  Prompt functions are Python functions that contain a template for the prompt in their docstring, and their arguments correspond to the variables used in the prompt. When called, a prompt function returns the template rendered with the values of the arguments.</p> <p>The aim of prompt functions is to solve several recurrent problems with prompting:</p> <ol> <li>Building complex prompts quickly leads to messy code. This problem has    already been solved in the web development community by using templating, so    why not use it here?</li> <li>Composing prompts is difficult. Why not just compose functions?</li> <li>Separating prompts from code. Encapsulation in functions allows a clean    separation between prompts and code. Moreover, like any function, prompt    functions can be imported from other modules.</li> </ol> <p>Prompts uses the Jinja templating engine to render prompts, which allows to easily compose complex prompts.</p> <p>Prompt rendering</p> <p>Prompt functions are opinionated when it comes to prompt rendering. These opinions are meant to avoid common prompting errors, but can have unintended consequences if you are doing something unusual. We advise to always print the prompt before using it. You can also read the reference section if you want to know more.</p> <p>Performance</p> <p>Prompt templates introduce some overhead compared to standard Python functions, although the rendering time is still very reasonable. In the unlikely scenario where rendering templates are a bottleneck you can replace them with functions that use standard string manipulation.</p>"},{"location":"reference/template/#your-first-prompt","title":"Your first prompt","text":"<p>The following snippet showcases a very simple prompt. The variables between curly brackets <code>{{  }}</code> are placeholders for the values of the arguments you will pass to the prompt function.</p> CodeOutput <pre><code>import prompts\n\n@prompts.template\ndef greetings(name, question):\n    return \"\"\"Hello, {{ name }}!\n    {{ question }}\n    \"\"\"\n\nprompt = greetings(\"user\", \"How are you?\")\nprint(prompt)\n</code></pre> <pre><code>Hello, user!\nHow are you?\n</code></pre> <p>If a variable is missing in the function's arguments, Jinja2 will throw an <code>UndefinedError</code> exception:</p> CodeOutput <pre><code>import prompts\n\n@prompts.template\ndef greetings(name):\n    return \"\"\"Hello, {{ surname }}!\"\"\"\n\nprompt = greetings(\"user\")\n</code></pre> <pre><code>Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 9, in &lt;module&gt;\n  File \"/home/remi/projects/normal/prompts/prompts.templates.py\", line 38, in __call__\n      return render(self.template, **bound_arguments.arguments)\n  File \"/home/remi/projects/normal/prompts/prompts.templates.py\", line 213, in render\n      return jinja_template.render(**values)\n  File \"/home/remi/micromamba/envs/prompts/lib/python3.9/site-packages/jinja2/environment.py\", line 1301, in render\n      self.environment.handle_exception()\n  File \"/home/remi/micromamba/envs/prompts/lib/python3.9/site-packages/jinja2/environment.py\", line 936, in handle_exception\n      raise rewrite_traceback_stack(source=source)\n  File \"&lt;template&gt;\", line 1, in top-level template code\n  jinja2.exceptions.UndefinedError: 'surname' is undefined\n</code></pre>"},{"location":"reference/template/#importing-prompt-functions","title":"Importing prompt functions","text":"<p>Prompt functions are functions, and thus can be imported from other modules:</p> prompts.pygenerate.pyOutput <pre><code>import prompts\n\n@prompts.template\ndef greetings(name, question):\n    return \"\"\"Hello, {{ name }}!\n    {{ question }}\n    \"\"\"\n</code></pre> <pre><code>from .prompts import greetings\n\nprompt = greetings(\"John Doe\", \"How are you today?\")\n</code></pre> <pre><code>Hello, John Doe!\nHow are you today?\n</code></pre>"},{"location":"reference/template/#few-shot-prompting","title":"Few-shot prompting","text":"<p>Few-shot prompting can lead to messy code. Prompt functions allow you to loop over lists or dictionaries from the template. In the following example we demonstrate how we can generate a prompt by passing a list of dictionaries with keys <code>question</code> and <code>answer</code> to the prompt function:</p> CodeOutput <pre><code>import prompts\n\n@prompts.template\ndef few_shots(instructions, examples, question):\n    return \"\"\"{{ instructions }}\n\n    Examples\n    --------\n\n    {% for example in examples %}\n    Q: {{ example.question }}\n    A: {{ example.answer }}\n\n    {% endfor %}\n    Question\n    --------\n\n    Q: {{ question }}\n    A:\n    \"\"\"\n\ninstructions = \"Please answer the following question following the examples\"\nexamples = [\n    {\"question\": \"2+2=?\", \"answer\":4},\n    {\"question\": \"3+3=?\", \"answer\":6}\n]\nquestion = \"4+4 = ?\"\n\nprompt = few_shots(instructions, examples, question)\nprint(prompt)\n</code></pre> <pre><code>Please answer the following question following the examples\n\nExamples\n--------\n\nQ: 2+2=?\nA: 4\n\nQ: 3+3=?\nA: 6\n\nQuestion\n--------\n\nQ: 4+4 = ?\nA:\n</code></pre>"},{"location":"reference/template/#conditionals-filters-etc","title":"Conditionals, filters, etc.","text":"<p>Jinja2 has many features beyond looping that are not described here: conditionals, filtering, formatting, etc. Please refer to the Jinja documentation for more information about the syntax of the templating language. The Jinja syntax is powerful, and we recommend you take some time to read their documentation if you are building complex prompts.</p>"},{"location":"reference/template/#formatting-conventions","title":"Formatting conventions","text":"<p>Prompt functions are opinionated when it comes to rendering, and these opinions are meant to avoid prompting mistakes and help with formatting.</p>"},{"location":"reference/template/#whitespaces","title":"Whitespaces","text":"<p>If you have experience working with strings between triple quotes you know that indenting has an influence on the string's formatting. Prompt functions adopt a few conventions so you don't have to think about indents when writing prompt.</p> <p>First, whether you start the prompt right after the triple quotes or on the line below does not matter for formatting:</p> CodeOutput <pre><code>import prompts\n\n@prompts.template\ndef prompt1():\n    return \"\"\"My prompt\n    \"\"\"\n\n@prompts.template\ndef prompt2():\n    return \"\"\"\n    My prompt\n    \"\"\"\n\nprint(prompt1())\nprint(prompt2())\n</code></pre> <pre><code>My prompt\nMy prompt\n</code></pre> <p>Indentation is relative to the second line of the docstring, and leading spaces are removed:</p> CodeOutput <pre><code>import prompts\n\n@prompts.template\ndef example1():\n    return \"\"\"First line\n    Second line\n    \"\"\"\n\n@prompts.template\ndef example2():\n    return \"\"\"\n      Second line\n      Third line\n    \"\"\"\n\n@prompts.template\ndef example3():\n    return \"\"\"\n      Second line\n        Third line\n    \"\"\"\n\nprint(example1())\nprint(example2())\nprint(example3())\n</code></pre> <pre><code>First line\nSecond line\n\nSecond line\nThird line\n\nSecond line\n  Third line\n</code></pre> <p>Trailing whitespaces are not removed, unless they follow a linebreak symbol <code>\\</code> (see linebreaks).</p>"},{"location":"reference/template/#linebreaks","title":"Linebreaks","text":"<p>You can use the backslash <code>\\</code> to break a long line of text. It will render as a single line:</p> CodeOutput <pre><code>import prompts\n\n@prompts.template\ndef example():\n   return \"\"\"\n   Break in \\\n   several lines \\\n   But respect the indentation\n       on line breaks.\n   And after everything \\\n   Goes back to normal\n   \"\"\"\n\nprint(example())\n</code></pre> <pre><code>Break in several lines But respect the indentation\n    on line breaks.\nAnd after everything Goes back to normal\n</code></pre>"}]}